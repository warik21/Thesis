{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import itertools\n",
    "import ot\n",
    "from utils.image import Image\n",
    "from utils.Visualizations import *\n",
    "from utils.utils import *\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be looking into three types of distances,\n",
    "\n",
    "The euclidean distance $L2$:\n",
    "$$L_2(\\mu, \\nu)=\\sum{|\\mu-\\nu|^2}$$\n",
    "\n",
    "The Wasserstein distance($W_2$):\n",
    "$$W_p(\\mu,\\nu)=inf_{\\pi\\in\\Pi(\\mu,\\nu)} \\bigg({ \\sum |x-y|^p \\cdot \\pi(x,y)}\\bigg)^\\frac{1}{p}$$\n",
    "\n",
    "The fourier distance ($f_{1,2}$):\n",
    "$$f_{1,2}(\\mu,\\nu)=\\bigg( \\frac{1}{|T|^2}\\int_{[0,T]^2} \\frac{|\\hat{\\mu}(k) - \\hat{\\mu}(k)|^2}{|k|^2} dk \\bigg)^\\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images dataset - v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image dataset will contain images created by simply creating two different images which have a zone of white pixels. \n",
    "Every image is created by adding a zone of ones to a zeros dataset.\n",
    "Only wasserstein and L2 distance will be calculated.\n",
    "\n",
    "we will denote the images by im1=p, im2=q:\n",
    "* $\\tilde{p} = p_+ + q_-$\n",
    "* $\\tilde{q} = q_+ + p_-$\n",
    "\n",
    "The Wasserstein distance will be calculated between the normalized and processed images $\\tilde{p}, \\tilde{q}$. \n",
    "\n",
    "The L2 distance will simply be calculated on the noised images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size_values = [int(x) for x in np.linspace(start=10, stop=50, num=5)]\n",
    "SNR_values = np.logspace(start=3, stop=-2, num=31)\n",
    "df_im_l1 = pd.DataFrame()\n",
    "distance_metric = 'L1' # 'L1' or 'L2'\n",
    "n_samples = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_size in tqdm.tqdm(im_size_values):\n",
    "    for SNR in SNR_values:\n",
    "        im1 = np.zeros((im_size, im_size))\n",
    "        im1[int(0.1 * im_size): int(0.3 * im_size), int(0.1 * im_size): int(0.3 * im_size)] = 1\n",
    "        im2 = np.zeros((im_size, im_size))\n",
    "        im2[int(0.7 * im_size): int(0.9 * im_size), int(0.7 * im_size): int(0.9 * im_size)] = 1 \n",
    "        \n",
    "        df_im_l1 = run_experiment_and_append_images(df=df_im_l1, im1=im1, im2=im2, SNR=SNR, \n",
    "                                                    distance_metric=distance_metric, \n",
    "                                                    n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images dataset - v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image dataset contains the distances between different images in the DOTMark dataset.\n",
    "\n",
    "We will denote the images by im1=p, im2=q:\n",
    "* $\\tilde{p} = p_+ + q_-$\n",
    "* $\\tilde{q} = q_+ + p_-$\n",
    "\n",
    "The Wasserstein anf Fourier distances will be calculated between the normalized and processed images $\\tilde{p}, \\tilde{q}$. \n",
    "\n",
    "The L2 distance will simply be calculated on the noised images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotmark_pictures_path = \"..\\\\DOTmark_1.0\\\\Pictures\\\\\"\n",
    "full_path = os.path.join(os.getcwd(), dotmark_pictures_path)\n",
    "resolutions = [32, 64, 128, 256, 512]\n",
    "image_numbers = ['01','02','03','04','05','06','07','08','09','10']\n",
    "categories_pattern = os.path.join(dotmark_pictures_path, \"*\")\n",
    "category_dirs = [path for path in glob.glob(categories_pattern) if os.path.isdir(path)]\n",
    "categories_pattern = os.path.join(dotmark_pictures_path, \"*\")\n",
    "category_names = [os.path.basename(category) for category in category_dirs if os.path.isdir(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = category_names[0]\n",
    "res = 32\n",
    "num_samples = 5\n",
    "category_dir = os.path.join(full_path, category)\n",
    "SNR_values = np.logspace(start=5, stop=1, num=31)\n",
    "noise_values = np.logspace(start=-5, stop=-1, num=31)\n",
    "pairs = list(itertools.combinations(image_numbers, 2))\n",
    "cost_matrix = calculate_costs((res, res))\n",
    "df_im_l1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SNR in tqdm(SNR_values):\n",
    "    noise_param = noise_from_SNR(SNR, 1, res)\n",
    "    for image_pair in pairs:\n",
    "        image1 = Image(res, category, image_pair[0], full_path)\n",
    "        image2 = Image(res, category, image_pair[1], full_path)\n",
    "\n",
    "        # Calculate original distances without noise\n",
    "        w1_dist_original, w1_time_original = calculate_and_time_wasserstein(image1.image, image2.image, cost_matrix)\n",
    "        f_dist_original, f_time_original = calculate_and_time_fourier1(image1.image, image2.image)\n",
    "        l2_dist_original, l2_time_original = calculate_and_time_l2(image1.image, image2.image)\n",
    "\n",
    "        results = Image.analyze_image_pair(image1, image2, cost_matrix, num_samples, noise_param)\n",
    "        w1_dist_noised, f_dist_noised, l2_dist_noised, time_w1, time_f, time_l2 = results\n",
    "\n",
    "        new_row = {\n",
    "            'Category': category,\n",
    "            'image1_index': image_pair[0],\n",
    "            'image2_index': image_pair[1],\n",
    "            'Noise': noise_param,\n",
    "            'SNR': SNR,\n",
    "            'Resolution': res,\n",
    "            'Wasserstein Original': w1_dist_original,\n",
    "            'Wasserstein Noised': w1_dist_noised,\n",
    "            'Wasserstein Ratio': w1_dist_original / w1_dist_noised,\n",
    "            'Wasserstein Time': time_w1,\n",
    "            'Fourier Original': f_dist_original, \n",
    "            'Fourier Noised': f_dist_noised,\n",
    "            'Fourier Ratio': f_dist_original / f_dist_noised,\n",
    "            'Fourier Time': time_f, \n",
    "            'L2 Original': l2_dist_original,\n",
    "            'L2 Noised': l2_dist_noised,\n",
    "            'L2 Ratio': l2_dist_original / l2_dist_noised,\n",
    "            'L2 Time': time_l2}  \n",
    "        \n",
    "        df_im_l1 = df_im_l1._append(new_row, ignore_index=True)\n",
    "df_im_l1.to_csv('results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images dataset - v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image dataset contains the distances between different images in the DOTMark dataset.\n",
    "\n",
    "We will denote the images by im1=p, im2=q:\n",
    "* $\\tilde{p} = p_+ + q_-$\n",
    "* $\\tilde{q} = q_+ + p_-$\n",
    "\n",
    "The Wasserstein distance will be calculated between the normalized and processed images $\\tilde{p}, \\tilde{q}$. \n",
    "\n",
    "The L2 and Fourier distances will simply be calculated on the noised images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotmark_pictures_path = \"..\\\\DOTmark_1.0\\\\Pictures\\\\\"\n",
    "full_path = os.path.join(os.getcwd(), dotmark_pictures_path)\n",
    "resolutions = [32, 64, 128, 256, 512]\n",
    "image_numbers = ['01','02','03','04','05','06','07','08','09','10']\n",
    "categories_pattern = os.path.join(dotmark_pictures_path, \"*\")\n",
    "category_dirs = [path for path in glob.glob(categories_pattern) if os.path.isdir(path)]\n",
    "categories_pattern = os.path.join(dotmark_pictures_path, \"*\")\n",
    "category_names = [os.path.basename(category) for category in category_dirs if os.path.isdir(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = category_names[0]\n",
    "res = 32\n",
    "num_samples = 5\n",
    "category_dir = os.path.join(full_path, category)\n",
    "SNR_values = np.logspace(start=5, stop=1, num=31)\n",
    "noise_values = np.logspace(start=-5, stop=-1, num=31)\n",
    "pairs = list(itertools.combinations(image_numbers, 2))\n",
    "cost_matrix = calculate_costs((res, res))\n",
    "df_im_l1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SNR in tqdm(SNR_values):\n",
    "    noise_param = noise_from_SNR(SNR, 1, res)\n",
    "    for image_pair in pairs:\n",
    "        image1 = Image(res, category, image_pair[0], full_path)\n",
    "        image2 = Image(res, category, image_pair[1], full_path)\n",
    "\n",
    "        # Calculate original distances without noise\n",
    "        w1_dist_original, w1_time_original = calculate_and_time_wasserstein(image1.image, image2.image, cost_matrix)\n",
    "        f_dist_original, f_time_original = calculate_and_time_fourier(image1.image, image2.image)\n",
    "        l2_dist_original, l2_time_original = calculate_and_time_l2(image1.image, image2.image)\n",
    "\n",
    "        results = Image.analyze_image_pair(image1, image2, cost_matrix, num_samples, noise_param)\n",
    "        w1_dist_noised, f_dist_noised, l2_dist_noised, time_w1, time_f, time_l2 = results\n",
    "\n",
    "        new_row = {\n",
    "            'Category': category,\n",
    "            'image1_index': image_pair[0],\n",
    "            'image2_index': image_pair[1],\n",
    "            'Noise': noise_param,\n",
    "            'SNR': SNR,\n",
    "            'Resolution': res,\n",
    "            'Wasserstein Original': w1_dist_original,\n",
    "            'Wasserstein Noised': w1_dist_noised,\n",
    "            'Wasserstein Ratio': w1_dist_original / w1_dist_noised,\n",
    "            'Wasserstein Time': time_w1,\n",
    "            'Fourier Original': f_dist_original, \n",
    "            'Fourier Noised': f_dist_noised,\n",
    "            'Fourier Ratio': f_dist_original / f_dist_noised,\n",
    "            'Fourier Time': time_f, \n",
    "            'L2 Original': l2_dist_original,\n",
    "            'L2 Noised': l2_dist_noised,\n",
    "            'L2 Ratio': l2_dist_original / l2_dist_noised,\n",
    "            'L2 Time': time_l2}  \n",
    "        \n",
    "        df_im_l1 = df_im_l1._append(new_row, ignore_index=True)\n",
    "df_im_l1.to_csv('results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images dataset v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
